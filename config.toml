[server]
port = 8125
host = "0.0.0.0"
frontend_url = "http://localhost:5173"  # Development frontend URL, empty in production
# HTTP server timeout for requests
http_server_timeout = "30s"

[sqlite]
path = "local.db"

[oidc]
# Use explicit URLs for each endpoint instead of discovery
# Provider URL for OIDC discovery - use service name for container-to-container communication
provider_url = "http://dex:5556/dex"
# Browser-facing auth URL - must match the domain/issuer used by DEX for browser communication
auth_url = "http://localhost:5556/dex/auth"
# Internal container-to-container token URL
token_url = "http://dex:5556/dex/token"

client_id = "logchef"
client_secret = "logchef-secret"
# Browser-facing redirect URL
redirect_url = "http://localhost:8125/api/v1/auth/callback"
scopes = ["openid", "email", "profile"]

[auth]
admin_emails = ["admin@logchef.internal"]
session_duration = "24h"
max_concurrent_sessions = 1
# Secret key for API token hashing (generate with: openssl rand -hex 32)
api_token_secret = "5679649c50fddda837449b77d9983ab5f8dba65878897e968a74e7061bf47677"
# Default API token expiration (empty for no expiration)
default_token_expiry = "2160h"  # 90 days = 90 * 24 = 2160 hours

[logging]
level = "debug"

# AI SQL generation configuration
[ai]
# Enable/disable AI features
enabled = true
# API endpoint
# Base URL for OpenAI API (leave empty for default OpenAI endpoint)
base_url = "https://openrouter.ai/api/v1"
# OpenAI API key for AI SQL generation
api_key = ""
# Model parameters
# Model to use (default: gpt-4o)
model = "gpt-4o"
# Maximum tokens to generate
max_tokens = 1024
# Temperature for generation (0.0-1.0, lower is more deterministic)
temperature = 0.1
